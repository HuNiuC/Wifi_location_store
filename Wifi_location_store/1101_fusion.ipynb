{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lixinhui/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import heapq\n",
    "import bottleneck\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mall_list = pd.read_csv('../others/mall_ID.csv',names=['mall_id'])\n",
    "mall_list = list(mall_list['mall_id'])\n",
    "\n",
    "f5 = open(\"../mydata/shop_label_dict.txt\",\"rb\")\n",
    "shop_label_dict = pickle.load(f5)\n",
    "f5.close()\n",
    "f6 = open(\"../mydata/label_shop_dict.txt\",\"rb\")\n",
    "label_shop_dict = pickle.load(f6)\n",
    "f6.close()\n",
    "\n",
    "f6 = open(\"../begain/wifi_count_dict.txt\",\"rb\")\n",
    "wifi_count_dict = pickle.load(f6)\n",
    "f6.close()\n",
    "f5 = open(\"../begain/wifi_value_dict.txt\",\"rb\")\n",
    "wifi_value_dict = pickle.load(f5)\n",
    "f5.close()\n",
    "\n",
    "df_train_data = pd.read_csv(\"../begain/df_train_data.csv\")\n",
    "df_vali_data= pd.read_csv(\"../begain/df_vali_data.csv\")\n",
    "df_test_data = pd.read_csv(\"../begain/df_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_1021\n",
      "Accuracy: 100.00%\n",
      "m_1085\n",
      "Accuracy: 100.00%\n",
      "m_1089\n",
      "Accuracy: 100.00%\n",
      "m_1175\n",
      "Accuracy: 99.95%\n",
      "m_1263\n",
      "Accuracy: 99.70%\n",
      "m_1293\n",
      "Accuracy: 99.92%\n",
      "m_1375\n",
      "Accuracy: 100.00%\n",
      "m_1377\n",
      "Accuracy: 100.00%\n",
      "m_1409\n",
      "Accuracy: 100.00%\n",
      "m_1621\n",
      "Accuracy: 99.87%\n",
      "m_1790\n",
      "Accuracy: 100.00%\n",
      "m_1831\n",
      "Accuracy: 100.00%\n",
      "m_1920\n",
      "Accuracy: 100.00%\n",
      "m_1950\n",
      "Accuracy: 99.86%\n",
      "m_2009\n",
      "Accuracy: 100.00%\n",
      "m_2058\n",
      "Accuracy: 100.00%\n",
      "m_2123\n",
      "Accuracy: 100.00%\n",
      "m_2182\n",
      "Accuracy: 100.00%\n",
      "m_2224\n",
      "Accuracy: 99.76%\n",
      "m_2267\n",
      "Accuracy: 99.68%\n",
      "m_2270\n",
      "Accuracy: 100.00%\n",
      "m_2333\n",
      "Accuracy: 100.00%\n",
      "m_2415\n",
      "Accuracy: 100.00%\n",
      "m_2467\n",
      "Accuracy: 100.00%\n",
      "m_2578\n",
      "Accuracy: 100.00%\n",
      "m_2715\n",
      "Accuracy: 100.00%\n",
      "m_2878\n",
      "Accuracy: 100.00%\n",
      "m_2907\n",
      "Accuracy: 100.00%\n",
      "m_3005\n",
      "Accuracy: 99.92%\n",
      "m_3019\n",
      "Accuracy: 100.00%\n",
      "m_3054\n",
      "Accuracy: 100.00%\n",
      "m_3112\n",
      "Accuracy: 100.00%\n",
      "m_3313\n",
      "Accuracy: 100.00%\n",
      "m_3425\n",
      "Accuracy: 100.00%\n",
      "m_3445\n",
      "Accuracy: 100.00%\n",
      "m_3501\n",
      "Accuracy: 100.00%\n",
      "m_3517\n",
      "Accuracy: 100.00%\n",
      "m_3528\n",
      "Accuracy: 99.75%\n",
      "m_3739\n",
      "Accuracy: 100.00%\n",
      "m_3832\n",
      "Accuracy: 100.00%\n",
      "m_3839\n",
      "Accuracy: 100.00%\n",
      "m_3871\n",
      "Accuracy: 99.81%\n",
      "m_3916\n",
      "Accuracy: 100.00%\n",
      "m_4011\n",
      "Accuracy: 100.00%\n",
      "m_4033\n",
      "Accuracy: 100.00%\n",
      "m_4079\n",
      "Accuracy: 99.72%\n",
      "m_4094\n",
      "Accuracy: 100.00%\n",
      "m_4121\n",
      "Accuracy: 100.00%\n",
      "m_4168\n",
      "Accuracy: 100.00%\n",
      "m_4187\n",
      "Accuracy: 100.00%\n",
      "m_4341\n",
      "Accuracy: 100.00%\n",
      "m_4406\n",
      "Accuracy: 100.00%\n",
      "m_4422\n",
      "Accuracy: 99.89%\n",
      "m_4459\n",
      "Accuracy: 100.00%\n",
      "m_4495\n",
      "Accuracy: 100.00%\n",
      "m_4515\n",
      "Accuracy: 100.00%\n",
      "m_4543\n",
      "Accuracy: 100.00%\n",
      "m_4548\n",
      "Accuracy: 100.00%\n",
      "m_4572\n",
      "Accuracy: 100.00%\n",
      "m_4759\n",
      "Accuracy: 100.00%\n",
      "m_4828\n",
      "Accuracy: 100.00%\n",
      "m_4923\n",
      "Accuracy: 100.00%\n",
      "m_5076\n",
      "Accuracy: 99.84%\n",
      "m_5085\n",
      "Accuracy: 100.00%\n",
      "m_5154\n",
      "Accuracy: 100.00%\n",
      "m_5352\n",
      "Accuracy: 100.00%\n",
      "m_5529\n",
      "Accuracy: 100.00%\n",
      "m_5767\n",
      "Accuracy: 100.00%\n",
      "m_5810\n",
      "Accuracy: 100.00%\n",
      "m_5825\n",
      "Accuracy: 100.00%\n",
      "m_5892\n",
      "Accuracy: 100.00%\n",
      "m_615\n",
      "Accuracy: 100.00%\n",
      "m_6167\n",
      "Accuracy: 100.00%\n",
      "m_622\n",
      "Accuracy: 100.00%\n",
      "m_623\n",
      "Accuracy: 99.67%\n",
      "m_625\n",
      "Accuracy: 99.86%\n",
      "m_626\n",
      "Accuracy: 100.00%\n",
      "m_6337\n",
      "Accuracy: 99.85%\n",
      "m_6587\n",
      "Accuracy: 99.85%\n",
      "m_6803\n",
      "Accuracy: 100.00%\n",
      "m_690\n",
      "Accuracy: 99.82%\n",
      "m_7168\n",
      "Accuracy: 100.00%\n",
      "m_7374\n",
      "Accuracy: 100.00%\n",
      "m_7523\n",
      "Accuracy: 99.81%\n",
      "m_7601\n",
      "Accuracy: 100.00%\n",
      "m_7800\n",
      "Accuracy: 99.91%\n",
      "m_7973\n",
      "Accuracy: 100.00%\n",
      "m_7994\n",
      "Accuracy: 100.00%\n",
      "m_8093\n",
      "Accuracy: 99.82%\n",
      "m_822\n",
      "Accuracy: 100.00%\n",
      "m_8344\n",
      "Accuracy: 100.00%\n",
      "m_8379\n",
      "Accuracy: 100.00%\n",
      "m_9054\n",
      "Accuracy: 100.00%\n",
      "m_9068\n",
      "Accuracy: 100.00%\n",
      "m_909\n",
      "Accuracy: 100.00%\n",
      "m_968\n",
      "Accuracy: 100.00%\n",
      "m_979\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "vali_label_list = []\n",
    "vali_predict_list = []\n",
    "forest_acc_dict_baseline ={}\n",
    "#mall_list2 = ['m_1263']#,'m_1175'\n",
    "#mall_list2 = ['m_2415']#m_1175'\n",
    "mall_list2 = ['m_1263']\n",
    "index_strength = ['s_0','s_1','s_2','s_3','s_4','s_5','s_6','s_7','s_8','s_9']\n",
    "index_bssid = ['b_0','b_1','b_2','b_3','b_4','b_5','b_6','b_7','b_8','b_9']\n",
    "for mall_id_ in mall_list:\n",
    "    \n",
    "    test_pre_path2  = '../begain/data_wifi/test_'+ mall_id_ +'.csv'\n",
    "    train_pre_path2 = '../begain/data_wifi/train_'+ mall_id_ +'.csv'\n",
    "    vali_pre_path2 = '../begain/data_wifi/vali_'+ mall_id_ +'.csv'\n",
    "    df_train_m = pd.read_csv(train_pre_path2,index_col =\"row_id\")\n",
    "    df_vali_m = pd.read_csv(vali_pre_path2,index_col =\"row_id\")\n",
    "    df_test_m = pd.read_csv(test_pre_path2,index_col =\"row_id\")\n",
    "    \n",
    "    save_path = '../data/1101/forest/test_'+ mall_id_ +'.csv'\n",
    "    test_pre_path3  = '../begain/data_wifi_vector_important/test_'+ mall_id_ +'.csv'\n",
    "    train_pre_path3 = '../begain/data_wifi_vector_important/train_'+ mall_id_ +'.csv'\n",
    "    vali_pre_path3 = '../begain/data_wifi_vector_important/vali_'+ mall_id_ +'.csv'\n",
    "   \n",
    "    test_pre_path4  = '../begain/baseline_xgboost/test_'+ mall_id_ +'.csv'\n",
    "    train_pre_path4 = '../begain/baseline_xgboost/train_'+ mall_id_ +'.csv'\n",
    "    vali_pre_path4 = '../begain/baseline_xgboost/vali_'+ mall_id_ +'.csv'\n",
    "    \n",
    "    df_train_w = pd.read_csv(train_pre_path3,index_col =\"row_id\")\n",
    "    df_vali_w = pd.read_csv(vali_pre_path3,index_col =\"row_id\")\n",
    "    df_test_w = pd.read_csv(test_pre_path3,index_col =\"row_id\")\n",
    "\n",
    "    df_train_xg = pd.read_csv(train_pre_path4,index_col =\"row_id\")\n",
    "    df_vali_xg = pd.read_csv(vali_pre_path4,index_col =\"row_id\")\n",
    "    df_test_xg = pd.read_csv(test_pre_path4,index_col =\"row_id\")\n",
    "    \n",
    "\n",
    "    df_train_m = df_train_m.join(df_train_w,how='left')\n",
    "    df_vali_m = df_vali_m.join(df_vali_w,how='left')\n",
    "    df_test_m = df_test_m.join(df_test_w,how='left')\n",
    "    \n",
    "#    df_train_m = df_train_m.join(df_train_xg,how='left')\n",
    "#    df_vali_m = df_vali_m.join(df_vali_xg,how='left')\n",
    "#    df_test_m = df_test_m.join(df_test_xg,how='left')\n",
    "    \n",
    "    train_data_row = df_train_m\n",
    "    vali_data_row = df_vali_m\n",
    "    test_data_row = df_test_m\n",
    "    \n",
    "    train_data_row['label']=train_data_row['shop_id']\n",
    "#    train_drop_list = list(train_data_row.columns)[0:7]\n",
    "    train_drop_list =[ 'user_id', 'shop_id', 'time_stamp', 'wifi_infos','mall_id']\n",
    "    train_data_drop = train_data_row.drop(train_drop_list, axis=1)\n",
    "    train_data_drop = train_data_drop.drop(index_bssid , axis=1)\n",
    "    train_data_drop = train_data_drop.drop(index_strength, axis=1)\n",
    "    train_data_drop['label']= train_data_drop['label'].apply(lambda x :shop_label_dict[mall_id_][x])\n",
    "  \n",
    "    vali_data_row['label']= vali_data_row['shop_id']\n",
    "#    vali_drop_list = list(vali_data_row.columns)[0:7]\n",
    "\n",
    "    vali_drop_list =[ 'user_id', 'shop_id', 'time_stamp', 'wifi_infos','mall_id']\n",
    "    vali_data_drop = vali_data_row.drop(vali_drop_list, axis=1)\n",
    "    vali_data_drop = vali_data_drop.drop(index_bssid , axis=1)\n",
    "    vali_data_drop = vali_data_drop.drop(index_strength, axis=1)\n",
    "    vali_data_drop['label']= vali_data_drop['label'].apply(lambda x :shop_label_dict[mall_id_][x])\n",
    "    train_data_all = train_data_drop.append(vali_data_drop)\n",
    "    \n",
    "    test_drop_list =[ 'user_id', 'time_stamp', 'wifi_infos','mall_id']\n",
    "    test_data_drop = test_data_row.drop(test_drop_list, axis=1)\n",
    "    test_data_drop = test_data_drop.drop(index_bssid , axis=1)\n",
    "    test_data_drop = test_data_drop.drop(index_strength, axis=1)\n",
    "    \n",
    "    \n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train_data_all['label'].values))\n",
    "    train_data_drop['label'] = lbl.transform(list(train_data_drop['label'].values)) \n",
    "    vali_data_drop['label'] = lbl.transform(list(vali_data_drop['label'].values)) \n",
    "    train_data_all['label'] = lbl.transform(list(train_data_all['label'].values))\n",
    "#    y_vali = vali_data_drop['label'].values\n",
    " #   train_data_drop = train_data_drop.append(vali_data_drop)\n",
    "    \n",
    "    np_train = np.array(train_data_all.fillna(value=0).values) \n",
    "    X_train = np_train[:,:-1] \n",
    "    y_train = np_train[:,-1].astype(int)\n",
    "    \n",
    "    \n",
    "#    np_train = np.array(train_data_drop.fillna(value=0).values) \n",
    "#    X_train = np_train[:,:-1] \n",
    "#    y_train = np_train[:,-1].astype(int)\n",
    "#    X_train = X_train[:,111:]\n",
    "        \n",
    "    np_vali = np.array(vali_data_drop.fillna(value=0).values) \n",
    "    X_vali = np_vali[:,:-1] \n",
    "    y_vali = np_vali[:,-1].astype(int)\n",
    "\n",
    "#    X_vali = X_vali[:,111:]\n",
    "    np_test = np.array(test_data_drop.fillna(value=0).values) \n",
    "    X_test = np_test\n",
    "    \n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators =100, min_samples_split=3,max_features=40,random_state=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    tree_model = clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_vali)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    vali_label_list.append(y_vali)\n",
    "    vali_predict_list.append(y_pred)\n",
    "    accuracy = accuracy_score(y_vali, predictions)\n",
    "    print mall_id_\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    forest_acc_dict_baseline[mall_id_] = accuracy\n",
    "    test_pre = clf.predict(X_test)\n",
    "    label_np = np.array(test_pre)\n",
    "#    columns_list = list(np.sort(train_data_drop['label'].unique()))\n",
    "    test_pre_df = pd.DataFrame(index = test_data_row.index, columns=['shop_id'],data = label_np)\n",
    "    test_pre_df['shop_id'] = test_pre_df['shop_id'].apply(lambda x:lbl.inverse_transform(int(x)))\n",
    "    test_pre_df.to_csv(save_path)\n",
    "forest_baseline = pd.Series(forest_acc_dict_baseline)\n",
    "forest_baseline.to_csv('../data/1101/forest/forest_baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mall_0 = mall_list[0]\n",
    "mall_other = mall_list[1:]\n",
    "df_pre = pd.read_csv('../data/1101/forest/test_'+ mall_0 +'.csv',index_col=['row_id'])\n",
    "df_pre['shop_id'] = df_pre['shop_id'].apply(lambda x :label_shop_dict[mall_0][int(x)])\n",
    "df_sub = df_pre\n",
    "for mall_id_ in mall_other:\n",
    "    test_pre_path = '../data/1101/forest/test_'+ mall_id_ +'.csv'\n",
    "    df_pre = pd.read_csv(test_pre_path,index_col=['row_id'])\n",
    "    df_pre['shop_id'] = df_pre['shop_id'].apply(lambda x :label_shop_dict[mall_id_][int(x)])\n",
    "    df_sub = df_sub.append(df_pre)\n",
    "df_sub.to_csv('../submit/1101/result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483931, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119090</th>\n",
       "      <td>s_783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119168</th>\n",
       "      <td>s_235089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119243</th>\n",
       "      <td>s_396464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119667</th>\n",
       "      <td>s_3816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119711</th>\n",
       "      <td>s_958323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          shop_id\n",
       "row_id           \n",
       "119090   s_783000\n",
       "119168   s_235089\n",
       "119243   s_396464\n",
       "119667  s_3816514\n",
       "119711   s_958323"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
